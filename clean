import pandas as pd

## raw dataset
file_path = '/Users/mattpritchett/Documents/INST462_project/MLB_Umpire_Raw_Data.csv'
umpire_data = pd.read_csv(file_path)


#Check for missing values
missing_values = umpire_data.isnull().sum()
print("Missing Values:\n", missing_values)

#Convert columns to numericc
numeric_columns = [
    "home_team_runs", "away_team_runs", "pitches_called",
    "incorrect_calls", "expected_incorrect_calls", "correct_calls",
    "expected_correct_calls", "correct_calls_above_expected", 
    "accuracy", "expected_accuracy", "accuracy_above_expected", 
    "consistency", "favor_home", "total_run_impact"
]
umpire_data[numeric_columns] = umpire_data[numeric_columns].apply(pd.to_numeric, errors='coerce')

#Convert 'date' column to datetime format
umpire_data['date'] = pd.to_datetime(umpire_data['date'], errors='coerce')

# check for duplicate rows and remove them
duplicates_count = umpire_data.duplicated().sum()
print(f"Duplicate Rows: {duplicates_count}")
umpire_data = umpire_data.drop_duplicates()

# cleaned dataset + summary statistics
print("Cleaned Dataset Preview:\n", umpire_data.head())
summary_statistics = umpire_data.describe()
print("Summary Statistics:\n", summary_statistics)

# Save cleaned data to a new CSV file
cleaned_file_path = '/Users/mattpritchett/Documents/INST462_project/MLB_Umpire_Cleaned_Data.csv'
umpire_data.to_csv(cleaned_file_path, index=False)
print(f"Cleaned data saved to: {cleaned_file_path}")